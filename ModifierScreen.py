#!/usr/bin/env python
__author__ = 'Sotaro Takano and Djordje Bajic'
__version__ = '1.0.1'

'''The codes for screening evolutionary capacitors and potentiators that significantly affects
flexibility of growth-rate ranks of the model. The functions were compatible with the results 
generated by "randomwalks.py" '''

import sys
import argparse
import routine_functions.CAFBA_mod as CF
from routine_functions.computing_growth_flux import *
import os
from os.path import join
from os.path import basename
from scipy import stats
import pandas as pd
import numpy as np
from pathlib import Path
import cobra
import pickle
from multiprocessing import Pool
import gc
import statsmodels.stats.multitest
import itertools
import copy

def sort_trajectories(args):

    '''Sorting evolutionary trajectrories in randomwalks by whether the reaction of interest 
    were mostly present or absent. In the case of default parameters (equivalent to those 
    in Takano et al., 2023), we classified a trajectory as "absent" if the reaction of interest 
    is mostly absent (> 70 %) in the last 7000 mutations, or classifed as "present" if the reaction
    of interest is mostly present (> 70 %) in the first 7000 mutations. '''

    rxn_target = args[0]
    allowable = args[1] # default:0.7
    time_range = args[2] # default:3000
    save_dir = args[3]
    resultdir = args[4]
        
    filename = join(save_dir,'TJgroup_' + str(rxn_target) + '.pkl')
    trajectories = [join(resultdir,x) for x in os.listdir(resultdir) if '.csv' in x]

    if os.path.exists(filename):
        print("%s is skipped."%rxn_target)
        return
    
    absent = []
    present = []
    

    for f in trajectories:
        exp_id = f.split("/")[-1].split(".")[0]
        result = pd.read_csv(join(resultdir,f),header = 0,index_col = 0)
        result[np.isnan(result)] = 0.0
        AddDel_list = [(n,x) for n,x in enumerate(result.index)]

        # In each evolutionary trajectory, we obtained list of time points
        # where the reaction of interest exists in the model. 
        exist_t = exist_timepoint(rxn_target, AddDel_list, base_rxns, exp_id)
        

        if len(exist_t[exist_t > time_range]) < (len(AddDel_list)-time_range)*(1-allowable):
            # If the reaction of interest is mostly absent in the last 7000 mutations, that trajectory is regarded as "absent" group. 
            absent.append(exp_id)
        elif len(exist_t[exist_t < (len(AddDel_list)-time_range)])>(len(AddDel_list)-time_range)*allowable:
            # If the reaction of interest is mostly present in the first 7000 mutations, that trajectory is regarded as "present" group. 
            present.append(exp_id)
            
    TJ_data = pd.DataFrame({rxn_target:[absent,present]}, index = ['absent','present'])
    
    filehandler = open(filename, 'wb')
    pickle.dump(TJ_data, filehandler)
    filehandler.close()
    gc.collect()



def exist_timepoint(target, rxn_list, base_rxns, expid):

    '''Return the list of timepoints where a reaction of interest exists in the model.'''
    
    exist = []
    events = [x for x in rxn_list if x[1].replace("add_","").replace("del_","") == target]
    
    if len(events) < 1:
        if target in base_rxns:
            exist = np.linspace(0,len(rxn_list)-1,len(rxn_list))
        else:
            exist = np.linspace(0,0,0)
        return exist
    
    for i,e in enumerate(events):
        if i == 0:
            start_t = 0
            if target in base_rxns: 
                pre_status = 1
            else:
                pre_status = 0
    
        if "del" in events[i][1]:
            if pre_status == 1:
                exist += [int(x) for x in np.linspace(start_t,events[i][0],(events[i][0]-start_t)+1)]
            else:
                print("something odd in %s in %s"%(target,expid))
            pre_status = 0
        
        elif "add" in events[i][1]:
            if pre_status == 0:
                pass
            else:
                print("something odd in %s in %s"%(target,expid))
            pre_status = 1

        start_t = events[i][0]

    if "del" in events[-1][1]:
        if pre_status == 0:
            pass
        else:
            print("something odd in %s in %s"%(target,expid))
        
    elif "add" in events[-1][1]:
        if pre_status == 1:
            exist += [int(x) for x in np.linspace(start_t,len(rxn_list),(len(rxn_list)-start_t)+1)]
        else:
            print("something odd in %s in %s"%(target,expid))
    
    return np.array(exist)


def compute_flips_individual(pkldata,l):
    flips = []
    combs = list(itertools.combinations(l,2))
    if len(pkldata) == len(combs):
        for i in l:
            target_combs = [combs.index(y) for y in [x for x in combs if x[0] == i or x[1] == i]]
            flips.append(sum([pkldata[x] for x in target_combs]))
        return flips
    else:
        return [np.nan]*len(l)


#################################
#### Main body of the script ####
#################################
if __name__ == "__main__":

    homedir = Path(__file__).parent.absolute()
    
    p = argparse.ArgumentParser(add_help=False)
    p.add_argument("-i","--inputdir", type=str, default="None", help="directory where result files of random walks exist")
    p.add_argument("-m","--model", type=str, default="None", help="an ancestral model for random walks")
    p.add_argument("-u","--universal",type=str,default="None", 
                   help="an universal model (This will be a pool of reactions for adding)")
    p.add_argument("-t","--threads", type=int, default=1, help="the number of threads")
    p.add_argument("-o","--optimizer", type=str, default="None", help="(optional) set an optimizer for FBA (e.g., gurobi) Default is cplex.")


    args = p.parse_args()

    # set solver
    if args.optimizer == "None":
        cobra.Configuration().solver = "cplex"
    else:
        cobra.Configuration().solver = args.optimizer

    if args.inputdir== "None":
        print("[WARN] The results directory of randomwalks must be specified by '--inputdir'.")
        print("[WARN] Using test data instead this time.")
        datadir = join(homedir,"test")
    else:
        datadir = args.inputdir
        if not os.path.exists(datadir): 
            sys.stderr.write("%s not exists...\n"%datadir)
            sys.exit()

    if args.model== "None":
        print("[MODEL] no model is set by -m option.")
        print("[MODEL] iJO1366 CAFBA is used as an ancestral model.")
        model_e_cafba = CF.CAFBA_mod_Model(
        cobra.io.read_sbml_model(
            join(homedir,'reference models','iJO1366_cafba.xml')
            )
        )

        model_e = CF.CAFBA_mod_Model(
            cobra.io.read_sbml_model(
                join(homedir,'reference models', 'iJO1366.xml'
                    )
            )
        )
    else:
        modelfile = args.model
        cafbafile = join(Path(modelfile).parent.absolute(),basename(modelfile).replace(".xml","_cafba.xml"))
        if modelfile.split(".")[-1] == "xml":
            model_e = CF.CAFBA_mod_Model(cobra.io.read_sbml_model(modelfile))
            if not os.path.exists(cafbafile):
                CF.main(modelfile)
            model_e_cafba = CF.CAFBA_mod_Model(cobra.io.read_sbml_model(cafbafile))
        else:
            print("[ERROR] an model file should be given as .xml file format")
            

    if args.universal== "None":
        print("[UNIVERSAL MODEL] no model is set by -m option.")
        print("[UNIVERSAL MODEL] CUiJO1366 is used as a reaction pool.")
        # Universal model (from Bajic et al. PNAS)
        # reversibility and upper and lower bounds are set using 'UiJO1366_default_bounds.csv'
        model_u_e = CF.CAFBA_mod_Model(
            cobra.io.read_sbml_model(
                join(homedir,'reference models', 'CUiJO1366_modified.xml')
            )
        )

        # I made CAFBA model from the above universal model
        model_u_e_cafba = CF.CAFBA_mod_Model(
            cobra.io.read_sbml_model(
                join(homedir,'reference models', 'CUiJO1366_modified_cafba.xml')
            )
        )
    else:
        universalfile = args.universal
        ucafbafile = join(Path(universalfile).parent.absolute(),
                          basename(universalfile).replace(".xml","_cafba.xml"))
        if universalfile.split(".")[-1] == "xml":
            model_u_e = CF.CAFBA_mod_Model(cobra.io.read_sbml_model(universalfile))
            if not os.path.exists(ucafbafile):
                CF.main(universalfile)
            model_u_e_cafba = CF.CAFBA_mod_Model(cobra.io.read_sbml_model(ucafbafile))
        else:
            print("[ERROR] an universal file should be given as .xml file format")
    
    
    #parentdir = Path(datadir).parent.absolute()
    
    '''We first picking out possible modifiers during random walks.
    As such, those reactions should not be exchange, demand, essential reactions.'''

    print("[RUNNING] Sorting out possible reactions for screening...")

    base_rxns = {x.id for x in model_e.reactions} 

    # Possible deletable reactions from the original model
    model_e_reactions = {x.id for x in model_e.reactions} 
    non_del_reactions = model_e.demand_reactions()
    non_del_reactions.add('ATPM')
    possible_dels = set(model_e_reactions - non_del_reactions) & {x.id for x in model_e_cafba.reactions}

    # Possible appendable reactions from the universal model
    total_reactions_id = {x.id for x in model_u_e.reactions}
    sink_rxns = {x.id for x in model_u_e.sinks}
    demand_rxns = {x.id for x in model_u_e.demands}
    exchange_rxns = {x.id for x in model_u_e.exchanges}
    possible_adds = total_reactions_id - set(sink_rxns | demand_rxns | exchange_rxns)
    possible_adds = (possible_adds - model_e_reactions) & {x.id for x in model_u_e_cafba.reactions}

    # Here I also excluded transporter reactions in a universal model from this experiment.
    possible_adds = possible_adds - set(model_u_e.transporters_list())

    # Merge the possible deletable and appendable reactions finally.
    total_reaction_set = list(possible_dels | possible_adds)

    
    print("[RUNNING] %s reactions are potentially modifiers in total..."%len(total_reaction_set))

    
    '''Sorting trajectrories by whether the reaction of interest were mostly present or absent first.'''

    save_dir = join(datadir,"Modifier_pkl")
    if not os.path.exists(save_dir):
        os.mkdir(save_dir)

    
    # those two parameters is equivalent to Takano et al., 2023
    allowable = 0.7
    time_range = 3000
    resultdir = join(datadir,"results")
    arguments = [(x,allowable,time_range,save_dir,resultdir) for x in total_reaction_set]
    print("[RUNNING] Sorting trajectories by the presence of the target reaction.")

    with Pool(processes=args.threads) as pool:
        pool.map(sort_trajectories,arguments)


    ''' Screening capacitors and potentiators based on the classification of trajectories'''
    # Eliminate irregular trajectories
    datapath = [join(resultdir,x) for x in os.listdir(resultdir) if '.csv' in x]
    droplist = []

    for f in datapath:
        exp_id = f.split("/")[-1].split(".")[0]
        result = pd.read_csv(join(resultdir,f),header = 0,index_col = 0)
        result[np.isnan(result)] = 0.0
        raveled = np.ravel(result)
        if len(raveled[raveled < 1e-06]) > 0:
            droplist.append(exp_id)


    ''' Summarize results (for individual sugars)) Screening capacitors and potentiators 
    for individual sugars with the flip counts'''

    print("[RUNNING] Screening evolutionary modifiers...")
    #total_reaction_set = [x.split("/")[-1].split(".")[0].replace("TJgroup_","") for x in os.listdir(save_dir) if ".pkl" in x]

    csource_list = result.columns.values
    met_list = [x[3:] for x in csource_list]
    pvalue_mets = ["pval_" + m for m in met_list]

    # Rank flips sensitivity
    Summary_flip_individual = pd.DataFrame(0,index = total_reaction_set,columns = met_list + pvalue_mets)

    # Summary of rank flips. These data is generated by "GrowthRank.py".
    Flip_individual = pd.read_csv(join(datadir,"rankchange_individual_sugars.csv"),index_col=0)


    summary_flip_individual = join(datadir, "Summary_modifiers_individual.csv")

    if not os.path.exists(summary_flip_individual):
        for i,rxn in enumerate(total_reaction_set):
            TJ_pklfile = [join(save_dir,x) for x in os.listdir(save_dir) if x.replace("TJgroup_","") == rxn + ".pkl"][0]
            TJ_pkl = pd.read_pickle(TJ_pklfile)

            presence = {x for x in TJ_pkl.loc["present",:][0] if x not in droplist} 
            absence = {x for x in TJ_pkl.loc["absent",:][0] if x not in droplist}

            flip_present = Flip_individual.loc[presence]     
            flip_absent = Flip_individual.loc[absence]

            delta_theta = [x for x in flip_absent.mean(axis=0) - flip_present.mean(axis=0)]
            pvalue = [x for x in stats.ttest_ind(flip_absent,flip_present)[1]]

            Summary_flip_individual.loc[rxn,:] = delta_theta + pvalue
        
        # p-value correction
        selected_fl = Summary_flip_individual.loc[~np.isnan(Summary_flip_individual.mean(axis=1)),:]
        selected_fl_corrected = copy.copy(selected_fl)
        for m in met_list:
            cor_pval = statsmodels.stats.multitest.multipletests(selected_fl["pval_" + m],method="hs")[1]
            selected_fl_corrected.loc[:,"pval_" + m] = cor_pval
        
        selected_fl_corrected["Modifier"] = 0
        selected_fl_corrected.loc[selected_fl_corrected[pvalue_mets].min(axis=1) < 0.01, "Modifier"] = 1
        selected_fl_corrected.to_csv(summary_flip_individual)
       
        print("[FINISHED] The result is saved %s"%summary_flip_individual)